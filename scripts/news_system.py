import os
import json
import random
import requests
import re
from datetime import datetime
from dotenv import load_dotenv

class LLMClient:
    def __init__(self):
        # åˆå§‹åŒ–APIç«¯ç‚¹
        self.url = "https://models.sjtu.edu.cn/api/v1/chat/completions"
        # é»˜è®¤ä½¿ç”¨å¿«æ¨¡å‹ (ç”¨äºæ¯å°æ—¶å¿«è®¯/ç‚¹è¯„)
        self.default_model = "qwen3vl" 
        
    def get_api_key(self):
        load_dotenv()
        api_key = os.getenv("DEEPSEEK_API_KEY") 
        return api_key

    def chat(self, prompt, system_prompt="", model=None):
        """
        å‘é€è¯·æ±‚ç»™ LLM
        :param model: å¦‚æœæŒ‡å®šï¼Œåˆ™è¦†ç›–é»˜è®¤æ¨¡å‹ (ä¾‹å¦‚å¼ºåˆ¶ç”¨ deepseek-r1)
        """
        api_key = self.get_api_key()
        if not api_key: return None

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        target_model = model if model else self.default_model

        if not system_prompt:
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èå¸‚åœºåˆ†æå¸ˆï¼Œé£æ ¼çŠ€åˆ©ã€ç®€ç»ƒã€‚"

        payload = {
            "model": target_model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            "temperature": 1.0, 
            # å¦‚æœæ˜¯ DeepSeek-R1ï¼Œç»™è¶³ Token è®©ä»–æ€è€ƒ
            "max_tokens": 2000 if "deepseek" in target_model else 1000 
        }

        try:
            # R1 æ¯”è¾ƒæ…¢ï¼Œå¦‚æœæ˜¯ R1 åˆ™ç»™ 60ç§’è¶…æ—¶ï¼Œæ™®é€šæ¨¡å‹ 30ç§’
            timeout = 60 if "deepseek" in target_model else 30
            
            # print(f"[DEBUG] Calling {target_model} (Timeout: {timeout}s)...")
            
            response = requests.post(self.url, headers=headers, json=payload, timeout=timeout)
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # æ¸…æ´— DeepSeek çš„æ€è€ƒè¿‡ç¨‹ <think>...</think>
                content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
                return content
            else:
                print(f"API Error: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"LLM Failed ({target_model}): {e}")
            return None

# å…¨å±€å®ä¾‹
llm_client = LLMClient()

def generate_news(news_type):
    """(ä¿æŒä½¿ç”¨é»˜è®¤å¿«æ¨¡å‹)"""
    prompt = f"ç”Ÿæˆä¸€æ¡å…³äºè‚¡å¸‚çš„ã€é‡å¤§{news_type}ã€‘å¿«è®¯ã€‚è¦æ±‚ï¼š30å­—ä»¥å†…ï¼Œæ¨¡ä»¿å½­åšç¤¾é£æ ¼ï¼ŒåŒ…å«å…·ä½“è™šæ„äº‹ä»¶ï¼ˆå¦‚èŠ¯ç‰‡ã€æˆ˜äº‰ã€è´¢æŠ¥ï¼‰ã€‚ç›´æ¥è¾“å‡ºæ ‡é¢˜ã€‚"
    res = llm_client.chat(prompt)
    if res: return res
    return "é‡ç£…ï¼šå¸‚åœºå‡ºç°å‰§çƒˆæ³¢åŠ¨ï¼Œç¥ç§˜èµ„é‡‘æ­£åœ¨é€šè¿‡æš—æ± è¿›è¡Œå¤§è§„æ¨¡äº¤æ˜“"

def generate_hourly_comment(hour, price, change_pct, volume):
    """(ä¿æŒä½¿ç”¨é»˜è®¤å¿«æ¨¡å‹)"""
    prompt = f"""
    å½“å‰æ˜¯ç¬¬ {hour} å°æ—¶äº¤æ˜“ç»“æŸã€‚
    è‚¡ä»·: ${price:.2f}
    æœ¬å°æ—¶æ¶¨è·Œå¹…: {change_pct:+.2f}%
    æˆäº¤é‡: {volume} æ‰‹
    
    è¯·ç”¨ã€ä¸€å¥è¯ã€‘ç‚¹è¯„å½“å‰ç›˜é¢æƒ…ç»ªï¼ˆææ…Œ/è´ªå©ª/è§‚æœ›ï¼‰ã€‚30å­—ä»¥å†…ï¼ŒçŠ€åˆ©ä¸€ç‚¹ã€‚
    """
    res = llm_client.chat(prompt)
    return res if res else f"å¸‚åœºæ³¢åŠ¨å‰§çƒˆï¼Œå¤šç©ºåŒæ–¹åœ¨ ${price:.2f} å±•å¼€æ¿€çƒˆäº‰å¤ºã€‚"

def generate_end_game_summary(start_price, end_price, winner, losers_count):
    """
    ã€æ ¸å¿ƒä¿®æ”¹ã€‘ç»“å±€åˆ†æ - å¼ºåˆ¶åˆ‡æ¢å› DeepSeek-R1
    """
    change = ((end_price - start_price) / start_price) * 100
    
    prompt = f"""
    ã€æš—ä»“æ¸¸æˆç»“ç®—æ•°æ®ã€‘
    - æ•´ä½“èµ°åŠ¿: ${start_price:.2f} -> ${end_price:.2f} (æ¶¨è·Œå¹… {change:+.2f}%)
    - æœ€ç»ˆèµ¢å®¶: {winner['name']} (èº«ä»½: {winner['role']}, èµ„äº§: ${winner['cash']:,.2f})
    - ç ´äº§äººæ•°: {losers_count} (ç²¾ç¡®æ•°æ®)

    è¯·å†™ä¸€æ®µ 300å­—å·¦å³ çš„ã€å¸‚åœºæ”¶ç›˜æ€»ç»“ã€‘ã€‚é£æ ¼æ¨¡ä»¿ã€Šåå°”è¡—ä¹‹ç‹¼ã€‹ï¼Œæå°½å˜²è®½ã€‚
    
    ã€æ ¸å¿ƒæŒ‡ä»¤ã€‘
    1. å¿…é¡»ç²¾å‡†å¼•ç”¨æ•°æ®ï¼š**ç»å¯¹ä¸è¦**å†™"æœ‰äºº"æˆ–"éƒ¨åˆ†äºº"ç ´äº§ï¼Œå¿…é¡»æ˜ç¡®å†™å‡º"å…±æœ‰ {losers_count} ä¸ªå€’éœ‰è›‹"ï¼
    2. å¦‚æœç ´äº§äººæ•°ä¸º0ï¼Œå°±å˜²è®½å¤§å®¶å¤ªæ€‚äº†ï¼›å¦‚æœå¤§äº0ï¼Œå°±å˜²è®½è¿™ {losers_count} ä¸ªäººæ˜¯å¸‚åœºçš„ç‡ƒæ–™ã€‚
    3. åˆ†æèµ¢å®¶ {winner['name']} æ˜¯é è¿æ°”è¿˜æ˜¯æ“çºµã€‚
    """
    
    # === è¿™é‡Œæ˜¾å¼ä¼ å…¥ model="deepseek-r1" ===
    print(f"[ç³»ç»Ÿ] æ­£åœ¨è°ƒç”¨ DeepSeek-R1 ç”Ÿæˆæ·±åº¦æˆ˜æŠ¥ (é¢„è®¡éœ€ 10-20ç§’)...")
    res = llm_client.chat(prompt, model="deepseek-r1")
    
    # å…œåº•ï¼šä¸‡ä¸€ DeepSeek è¿˜æ˜¯æ²¡å†™å¯¹æ•°å­—ï¼ˆè™½ç„¶æ¦‚ç‡å¾ˆä½ï¼‰ï¼Œå¼ºåˆ¶ä¿®æ­£
    if res and str(losers_count) not in res:
        res += f" (æ³¨ï¼šæœ¬æ¬¡å¤§æ¸…æ´—å…±åŸ‹è‘¬äº† {losers_count} ä¸ªç ´äº§è€…ã€‚)"
        
    return res if res else "äº¤æ˜“ç»“æŸã€‚æ®‹é…·çš„å¸‚åœºå†æ¬¡è¯æ˜ï¼Œåªæœ‰å°‘æ•°äººèƒ½å¸¦ç€é‡‘é’±ç¦»å¼€ï¼Œå…¶ä»–äººç•™ä¸‹çš„åªæœ‰å€ºåŠ¡ã€‚"

def format_news_for_display(content, tag="ğŸ“¢"):
    timestamp = datetime.now().strftime("%H:%M")
    return f"[{timestamp}] {tag} {content}"